{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06c733a-1124-44b5-a634-37d0887fdfe6",
   "metadata": {},
   "source": [
    "# BUT WAIT, THERE'S MORE...\n",
    "\n",
    "Just before we move on, there's one more pricer I want to show you\n",
    "\n",
    "## The MOST POWERFUL MODEL that I've ever demoed live\n",
    "\n",
    "Recap on our best 2 models so far:\n",
    "\n",
    "- GPT-4.1 with RAG got to **\\$50.72**\n",
    "- Our fine-tuned model got to **\\$46.67**\n",
    "\n",
    "Can we do better??\n",
    "\n",
    "## You may be familiar with the technique called \"Ensembling\" - combining different models\n",
    "\n",
    "It turns out that often you can find ways to combine 2 different models, and the results can outperform either of the models indidually.\n",
    "\n",
    "The first time you hear it, it can sound counter-intuitive.\n",
    "\n",
    "But let's see! To keep it simple, we'll just take the average prediction from the 2 models...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db71ba5-55a8-48b7-97d5-9db8dc872837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from evaluator import evaluate\n",
    "from chromadb import PersistentClient\n",
    "from litellm import completion\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044d040-e467-4463-a3a5-119939ca8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cb7f1-41f7-4df8-95fa-f3143b4ce312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to HuggingFace\n",
    "# If you don't have a HuggingFace account, you can set one up for free at www.huggingface.co\n",
    "# And then add the HF_TOKEN to your .env file as explained in the project README\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(token=hf_token, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba77914-ea9a-4b92-9280-863ee07ca8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PersistentClient(path=DB)\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "collection_name = \"products\"\n",
    "collection = client.get_or_create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa837b98-17ff-486e-ac30-a4b4f794af7b",
   "metadata": {},
   "source": [
    "## With that background, let's populate our Chroma database\n",
    "\n",
    "### By calculating vectors for 400,000 scraped products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f14728-b797-49ed-9aad-e98ea6946b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270b0ad-5a8f-4e54-a852-f16992314e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test pickle file\n",
    "\n",
    "with open('../test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a25b1-f93c-4a75-9999-09e262f9abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to give some context to OpenAI by selecting 5 products with similar descriptions\n",
    "\n",
    "def make_context(similars, prices):\n",
    "    message = \"To provide some context, here are some other items that might be similar to the item you need to estimate.\\n\\n\"\n",
    "    for similar, price in zip(similars, prices):\n",
    "        message += f\"Potentially related product:\\n{similar}\\nPrice is ${price:.2f}\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b57490-060d-47ff-9cf0-2b61b455bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(item, similars, prices):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = make_context(similars, prices)\n",
    "    user_prompt += \"And now the question for you:\\n\\n\"\n",
    "    user_prompt += item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cccac3-c0de-4d36-9803-20c8bd1762fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    message = f\"Reply with a 2-3 sentence summary of this product. This will be used to find similar products so it should be clear, concise, complete. Details:\\n{item}\"\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    response = completion(model=\"groq/openai/gpt-oss-20b\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99ce28-7e42-45df-9aa3-e115332f9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(item):\n",
    "    text = preprocess(item.text)\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471584f-4998-469f-8c7f-cd7ffc74b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars(item):\n",
    "    vec = vector(item)\n",
    "    results = collection.query(query_embeddings=vec.astype(float).tolist(), n_results=5)\n",
    "    documents = results['documents'][0][:]\n",
    "    prices = [m['price'] for m in results['metadatas'][0][:]]\n",
    "    return documents, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700ba02-a84b-432b-896a-29de50b85569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function that extracts a price from a response from GPT-4.1-mini\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ab130-b6d8-4356-9704-687c9bc2636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for gpt-4.1\n",
    "\n",
    "def gpt_4_1_rag(item):\n",
    "    documents, prices = find_similars(item)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\", \n",
    "        messages=messages_for(item, documents, prices),\n",
    "        seed=42,\n",
    "        max_tokens=8\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab66332-80cf-4404-a960-46616914f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "Pricer = modal.Cls.from_name(\"pricer-service\", \"Pricer\")\n",
    "pricer = Pricer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d364c0-db04-49a4-8216-81445c5b406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_of_frontier_with_RAG_and_fine_tuned(item):\n",
    "    price1 = gpt_4_1_rag(item)\n",
    "    description = item.test_prompt().replace(\"How much does this cost to the nearest dollar?\\n\\n\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    price2 = pricer.price.remote(description)\n",
    "    return (price1 + price2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba307b1-8daa-4e45-81b6-52d44acaef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(ensemble_of_frontier_with_RAG_and_fine_tuned, test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a50296-c7a5-4977-b97f-d1f7f2c241e6",
   "metadata": {},
   "source": [
    "# AMAZING!\n",
    "\n",
    "I hope you enjoyed this result.\n",
    "\n",
    "But here's the thing: you can do better!\n",
    "\n",
    "Other students have got this into the lower 30s..\n",
    "\n",
    "- Experiment with more models\n",
    "- Use different encoders\n",
    "- Use an LLM to pre-process descriptions\n",
    "- Use the Deep Neural network\n",
    "- Make a new Ensemble of all these models\n",
    "\n",
    "You should be able to get there too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bde8f-a124-44a2-8da2-c9ac749fc544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

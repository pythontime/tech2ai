{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae2b3a2-02d4-4061-9639-3a6f09810a44",
   "metadata": {},
   "source": [
    "# Fifth Agent Agent\n",
    "\n",
    "Introducing a critical agent - the agent that brings it all together.\n",
    "\n",
    "# Planning Agent\n",
    "\n",
    "There are a number of frameworks out there that support building Agentic Workflows.\n",
    "\n",
    "OpenAI has OpenAI Agents SDK, LangChain has LangGraph, and there's Autogen from Microsoft, Crew.ai and many others.  \n",
    "\n",
    "Each of these are abstractions on top of APIs to LLMs; some are lightweight, others come with significant functionality.\n",
    "\n",
    "It's also perfectly possible - and sometimes considerably easier - to build an agentic solution by calling LLMs directly.\n",
    "\n",
    "There's been considerable convergence on LLM APIs, and it's not clear that there's a need to sign up for one of the agent ecosystems for many use cases.\n",
    "\n",
    "Anthropic has an [insightful post](https://www.anthropic.com/research/building-effective-agents) on building effective Agentic architectures that's well worth a read.\n",
    "\n",
    "# We are going to use OpenAI Agents SDK for this Agent\n",
    "\n",
    "## And we're using Tools to give our Agent autonomy\n",
    "\n",
    "In our case, we're going to create an Agent that uses Tools to make decisions about what to do next.\n",
    "\n",
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f171c2b-1943-43a5-85c6-0bcd84bdd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc09be7-0666-4fd4-8699-78e2c0cac93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't go in depth into OpenAI Agents SDK but it's super easy and convenient!\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "from agents.mcp import MCPServerStdio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c8116-e4b6-4332-8bdb-d7c90b4aa9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL = \"gpt-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896c5f3-1ecc-4464-b913-2e7cfe29c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Scanner agent from before\n",
    "\n",
    "from price_agents.scanner_agent import ScannerAgent\n",
    "scanner = ScannerAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f25eed-e48a-4f9a-9817-4c0451378b40",
   "metadata": {},
   "source": [
    "# Our tools\n",
    "\n",
    "The next 3 cells have 3 **fake** functions that we will allow our LLM to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f920a35-c58d-4961-8c3c-40d70157da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def scan_the_internet_for_bargains() -> str:\n",
    "    \"\"\" This tool scans the internet for great deals and gets a curated list of promising deals \"\"\"\n",
    "    print(\"Fake function to scan the internet - this returns a hardcoded set of deals\")\n",
    "    results = scanner.test_scan()\n",
    "    return results.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f885983-e054-43f3-86b4-6db9323216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def estimate_true_value(description: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool estimates the true value of a product based on a text description of it\n",
    "\n",
    "    Args:\n",
    "        description: a description of the product to be estimated\n",
    "    \"\"\"\n",
    "    print(f\"Fake function to estimating true value of {description[:20]}... - this always returns $300\")\n",
    "    result = {\"description\": description, \"estimated_true_value\": 300}\n",
    "    return json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a42f55-0f75-44b1-830f-ee13d161cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def notify_user_of_deal(description: str, deal_price: float, estimated_true_value: float) -> str:\n",
    "    \"\"\"\n",
    "    This tool notifies the user of a great deal, given a description of it, the price of the deal, and the estimated true value\n",
    "\n",
    "    Args:\n",
    "        description: a description of the product with the deal\n",
    "        deal_price: how much the product is being offered for\n",
    "        estimated_true_value: an estimate of how much this product is actually worth\n",
    "        url: the web address of the product\n",
    "    \"\"\"\n",
    "    print(f\"Fake function to notify user of {description} which costs {deal_price} and estimate is {estimated_true_value}\")\n",
    "    return \"notification sent ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dd672-e77e-4f91-a66d-fe67f10ac093",
   "metadata": {},
   "source": [
    "## Telling the LLM about the tools it can use, with JSON\n",
    "\n",
    "\"Tool calling\" is giving an LLM the power to run code on your computer!\n",
    "\n",
    "Sounds a bit spooky?\n",
    "\n",
    "The way it works is a little more mundane. We give the LLM a description of each Tool and the parameters, and we let it inform us if it wants any tool to be run.\n",
    "\n",
    "See this conversation I had with ChatGPT and see if it is revealing for you!\n",
    "\n",
    "https://chatgpt.com/share/6856f9aa-c8b4-8012-abdc-09f5da82aa4e\n",
    "\n",
    "It's not like OpenAI reaches in and runs a function. In the end, we have an if statement that calls our function if the model requests it.\n",
    "\n",
    "## OpenAI Agents SDK has made this easy for us\n",
    "\n",
    "The decorator `function_tools` around each of our functions automatically generates the description we need for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe26fb-ba16-4aee-9e25-a772e7d15317",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify_user_of_deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbeb16b-749e-437f-a65a-24b0a5bcde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify_user_of_deal.params_json_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1d76a-8744-46d0-afb3-d881820d876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [scan_the_internet_for_bargains, estimate_true_value, notify_user_of_deal]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088a008-fed8-4bc6-8041-8801adb3754c",
   "metadata": {},
   "source": [
    "## And.. MCP\n",
    "\n",
    "The Model Context Protocol from Anthropic is causing a lot of excitement.\n",
    "\n",
    "It gives us a really easy way to integrate new capabilities with our agent, as more tools.\n",
    "\n",
    "Here we will give our agent powers to write to our local filesystem in a directory \"sandbox\"\n",
    "\n",
    "MCP is covered in more detail in other sessions (linked in resources) but the basics:\n",
    "\n",
    "1. You describe them using parameters\n",
    "2. You create them with `with MCPServerStdio(params=params) as server`\n",
    "3. You can call `server.session.list_tools()` or pass in `server` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b825e-df74-412f-a829-2a4c92cf1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "\n",
    "# parameters describe an MCP server\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=30) as server:\n",
    "    file_tools = await server.session.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83173856-54d4-4afd-ac13-83fa15eca766",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tools.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195e6ad-c838-4a5f-ab3c-f3cb7f470fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "You are an Autonomous AI Agent that makes use of tools to carry out your mission.\n",
    "Your mission is to find great deals on bargain products, and notify the user with a push notification and a written file.\n",
    "First scan the internet for bargains. Then for each deal, estimate its true value - how much it's actually worth.\n",
    "Finally, pick the single most compelling deal where the deal price is much lower than the estimated true value, and \n",
    "send the user a push notification about that deal, and also write or update a file called sandbox/deals.md with a description in markdown.\n",
    "You must only notify the user about one deal, and be sure to pick the most compelling deal.\n",
    "Then just respond OK to indicate success.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cad2e-a470-4cb7-ad78-3a13352bf4c5",
   "metadata": {},
   "source": [
    "### And here's where it comes together - just 2 lines of code\n",
    "\n",
    "Keep in mind: this will use the Tools we provided it, which are the fake functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3021830-b216-4013-8456-671a370f4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=60) as server:\n",
    "    agent = Agent(name=\"Planner\", model=MODEL, tools=tools, mcp_servers=[server])\n",
    "    result = await Runner.run(agent, task)\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67020429-93a3-4c26-b4ae-7c9c9f1d41a2",
   "metadata": {},
   "source": [
    "## And now - putting all of this into a Planning Agent\n",
    "\n",
    "But instead of these Fake Functions, this Planning Agent will actually call the other Agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b1875-3a42-41c0-b217-9789090347b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from price_agents.autonomous_planning_agent import AutonomousPlanningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767db7b9-8d78-4d02-9b79-6c5e2dd8ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbf6c0-301e-4da0-b4e3-8f91ab4d686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "DB = \"products_vectorstore\"\n",
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208067d9-8396-4f95-8dc8-a614c9a455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AutonomousPlanningAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121edc8-c309-4d04-b737-16a4235a83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c43c38-46d5-4186-880c-439ec975bb4b",
   "metadata": {},
   "source": [
    "### Check out the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e15e5-dddc-4f2e-bbb4-ab9a5392eca7",
   "metadata": {},
   "source": [
    "# Finally - with a Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6f9da59-43c4-409f-8a93-5993e1d9e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset memory back to 2 deals discovered in the past\n",
    "\n",
    "from deal_agent_framework import DealAgentFramework\n",
    "DealAgentFramework.reset_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805095ad-9d07-4869-9432-338f87fb65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run price_is_right.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df197f7-7ed4-4b24-a333-80ffda9d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put modal back to sleeping after 2 minutes\n",
    "\n",
    "import modal\n",
    "Pricer = modal.Cls.from_name(\"pricer-service\", \"Pricer\")\n",
    "pricer = Pricer()\n",
    "pricer.update_autoscaler(scaledown_window=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
